import openai
from openai import OpenAI
import json
import os
from dotenv import load_dotenv
from fetch_articles import extract_article_text


load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))




def summarize_text(text, max_tokens=200):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo", 
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è¦ç´„ãŒå¾—æ„ãªAIã§ã™ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ãªã©ã«å¿…è¦ãªäº‹ã‚’æŠœãå‡ºã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": f"ä»¥ä¸‹ã®å†…å®¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã«é‡è¦ãªäº‹ãªã©ã‚’è¦ç´„ã—ã¦:\n{text}"}
        ],
        max_tokens=max_tokens,
        temperature=0.5
    )
    return response.choices[0].message.content


def summarize_articles(input_file="999_articles.json", output_file="999_summaries.json"):
    with open(input_file, "r", encoding="utf-8") as f:
        articles = json.load(f)

    summaries = []

    for i, article in enumerate(articles):
        print(f"ğŸ“˜ {i+1}ä»¶ç›®ï¼šã€Œ{article['title']}ã€ã®æœ¬æ–‡èª­ã‚“ã§ã‚‹ã‚ˆã€œ")
        article_text = extract_article_text(article['url'])

        if not article_text:
            article_text = article['title']

        summary = summarize_text(article_text[:3000])  # é•·ã™ãé˜²æ­¢
        summaries.append({
            "title": article["title"],
            "url": article["url"],
            "summary": summary
        })

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(summaries, f, indent=2, ensure_ascii=False)

    print("âœ… è¦ç´„ãœã‚“ã¶çµ‚ã‚ã£ãŸã‚ˆã€œâ™¡")